{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import pca\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取MNIST数据\n",
    "* 两组数据\n",
    "* 1. train 1-2000, test 2001-4000\n",
    "* 2. train 2001-4000, test 1-2000\n",
    "* 数据是按0-9的顺序排列的，每个数字有两百个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(flag=1,normalize=False):\n",
    "    \"\"\"\n",
    "    flag: 选择两组数据中的某一个\n",
    "    normalize: 数据是否要正则化 (在训练某些model的时候好像有bug，待研究)\n",
    "    \n",
    "    return: X_train, Y_train, X_test, Y_test\n",
    "    \"\"\"\n",
    "    labels = get_data('digits4000_txt/digits4000_digits_labels.txt')\n",
    "    digits = get_data('digits4000_txt/digits4000_digits_vec.txt')\n",
    "\n",
    "    if flag==1:\n",
    "        X_train = digits[:2000]\n",
    "        Y_train = labels[:2000]\n",
    "        X_test = digits[2000:]\n",
    "        Y_test = labels[2000:]\n",
    "    else:\n",
    "        X_train = digits[2000:]\n",
    "        Y_train = labels[2000:]\n",
    "        X_test = digits[:2000]\n",
    "        Y_test = labels[:2000]\n",
    "\n",
    "    if normalize:\n",
    "        X_train = X_train/255\n",
    "        Y_train = Y_train/255\n",
    "        X_test = X_test/255\n",
    "        Y_test = Y_test/255\n",
    "\n",
    "    return np.array(X_train),np.array(Y_train),np.array(X_test),np.array(Y_test)\n",
    "\n",
    "def get_data(filename):\n",
    "    return np.loadtxt(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data(flag=1,normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各种Classifier的实现\n",
    "\n",
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(train_x,train_y):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    model = KNeighborsClassifier()\n",
    "    model.fit(train_x, train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_classifier(train_x, train_y):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    model = LogisticRegression(penalty='l2')\n",
    "    model.fit(train_x, train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_classifier(train_x, train_y):\n",
    "    from sklearn import tree\n",
    "    model = tree.DecisionTreeClassifier()\n",
    "    model.fit(train_x, train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_classifier(train_x, train_y):\n",
    "    from sklearn.svm import SVC\n",
    "    model = SVC(kernel='rbf', gamma=0.01, C=1) # 选择kernel之后，rbf的准确率比其他的高，参数还没研究过\n",
    "    model.fit(train_x, train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifier(train_x, train_y, num_classes=10):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(train_x, train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model\n",
    "* 模型参数直接在这个里面改\n",
    "* CNN不需要进行PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_classifier(train_x, train_y):\n",
    "    train_X = train_x.reshape(-1, 1, 28, 28)\n",
    "    train_Y = np_utils.to_categorical(train_y, num_classes=10)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Convolution2D(filters=32,\n",
    "                                        kernel_size=5,\n",
    "                                        strides=1,\n",
    "                                        padding='same',\n",
    "                                        batch_input_shape=(None, 1, 28, 28),\n",
    "                                        data_format='channels_first'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2, \n",
    "                                       strides=2, \n",
    "                                       padding='same', \n",
    "                                       data_format='channels_first'))\n",
    "    model.add(Convolution2D(64, 5, \n",
    "                                        strides=1, \n",
    "                                        padding='same', \n",
    "                                        data_format='channels_first'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = Adam(lr=1e-4)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(train_X, train_Y, epochs=20, batch_size=64)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN model\n",
    "* 和CNN model相似，结构不一样\n",
    "* DNN可以进行PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_classifier(train_x, train_y):\n",
    "    batch_size = 100\n",
    "    nb_classes = 10\n",
    "    nb_epoch = 20\n",
    "    \n",
    "    train_y = np_utils.to_categorical(train_y, num_classes=10)\n",
    "    \n",
    "    input_dim = train_x.shape[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(input_dim,)))\n",
    "    \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "    model.fit(train_x, train_y, batch_size=batch_size, epochs=nb_epoch)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用PCA降维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_model(train_x,components=600):\n",
    "    model = pca.PCA(n_components=components).fit(train_x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training和testing的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['knn_classifier','logistic_regression_classifier','decision_tree_classifier','svm_classifier','random_forest_classifier','cnn_classifier','dnn_classifier']\n",
    "# classifiers = ['knn_classifier','logistic_regression_classifier','decision_tree_classifier','svm_classifier','dnn_classifier'] # test\n",
    "x_train, y_train, x_test, y_test = load_data(flag=1,normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_process(classifiers, x_train, y_train, x_test, y_test):\n",
    "    result = {}\n",
    "    for classifier in classifiers:\n",
    "        try:\n",
    "            print(\"=======================\")\n",
    "            print('Classifier: {}'.format(classifier))\n",
    "            temp_model = eval(classifier)(x_train,y_train) \n",
    "    \n",
    "            if classifier == 'cnn_classifier': # CNN需要转换一下数据格式\n",
    "                x_test_reshape = x_test.reshape(-1, 1, 28, 28)\n",
    "                y_test_reshape = np_utils.to_categorical(y_test, num_classes=10)\n",
    "                loss, accuracy = temp_model.evaluate(x_test_reshape, y_test_reshape)\n",
    "            else:\n",
    "                if classifier == 'dnn_classifier':\n",
    "                    y_test_reshape = np_utils.to_categorical(y_test, num_classes=10)\n",
    "                    loss, accuracy = temp_model.evaluate(x_test, y_test_reshape)\n",
    "                else:\n",
    "                    y_train_predict = temp_model.predict(x_train)\n",
    "                    training_accuracy = metrics.accuracy_score(y_train,y_train_predict)\n",
    "                    print('training accuracy: {}'.format(\"%.2f%%\"%( 100*training_accuracy)))\n",
    "                    y_predict = temp_model.predict(x_test)\n",
    "                    accuracy = metrics.accuracy_score(y_test, y_predict)\n",
    "                \n",
    "            print('testing accuracy: {}'.format(\"%.2f%%\"%( 100*accuracy)))\n",
    "            result[classifier] = accuracy\n",
    "        except:\n",
    "            print('+++++++++++++++++++++++++')\n",
    "            print('Error with {}.'.format(classifier))\n",
    "            import traceback\n",
    "            print(traceback.format_exc())\n",
    "            print('+++++++++++++++++++++++++')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 没有normalization和PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Classifier: knn_classifier\n",
      "training accuracy: 94.50%\n",
      "testing accuracy: 91.70%\n",
      "=======================\n",
      "Classifier: logistic_regression_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 83.45%\n",
      "=======================\n",
      "Classifier: decision_tree_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 71.85%\n",
      "=======================\n",
      "Classifier: svm_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 10.00%\n",
      "=======================\n",
      "Classifier: random_forest_classifier\n",
      "training accuracy: 99.80%\n",
      "testing accuracy: 84.80%\n",
      "=======================\n",
      "Classifier: cnn_classifier\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 11.5333 - acc: 0.2725\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 11.3827 - acc: 0.2920\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 11.3488 - acc: 0.2945\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 11.3317 - acc: 0.2945\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 11.3086 - acc: 0.2975\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 11.3483 - acc: 0.2945\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 11.3122 - acc: 0.2970\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 11.3795 - acc: 0.2930\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 11.3088 - acc: 0.2975\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 11.2911 - acc: 0.2995\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 11.2988 - acc: 0.2990\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 11.2988 - acc: 0.2990\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 11.2988 - acc: 0.2990\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 11.2988 - acc: 0.2990\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 11.2988 - acc: 0.2990\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 11.2988 - acc: 0.2990\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 11.2988 - acc: 0.2990\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 11.2988 - acc: 0.2990\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 11.2988 - acc: 0.2990\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 11.2988 - acc: 0.2990\n",
      "2000/2000 [==============================] - 6s 3ms/step\n",
      "testing accuracy: 29.75%\n",
      "=======================\n",
      "Classifier: dnn_classifier\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 13.0787 - acc: 0.1840\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 0s 142us/step - loss: 12.7530 - acc: 0.2065\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 0s 144us/step - loss: 12.0873 - acc: 0.2485\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 0s 143us/step - loss: 11.9687 - acc: 0.2570\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 0s 144us/step - loss: 11.6752 - acc: 0.2750\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 0s 145us/step - loss: 11.8714 - acc: 0.2620\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 0s 149us/step - loss: 11.3134 - acc: 0.2965\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 0s 163us/step - loss: 11.0571 - acc: 0.3125\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 0s 169us/step - loss: 11.0993 - acc: 0.3090\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 0s 141us/step - loss: 10.5069 - acc: 0.3480\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 0s 162us/step - loss: 11.1120 - acc: 0.3095\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 0s 170us/step - loss: 11.6485 - acc: 0.2770\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 0s 164us/step - loss: 11.6910 - acc: 0.2740\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 0s 175us/step - loss: 11.2721 - acc: 0.3005\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 0s 147us/step - loss: 10.4972 - acc: 0.3475\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 0s 145us/step - loss: 10.4164 - acc: 0.3525\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 0s 166us/step - loss: 10.4625 - acc: 0.3500\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 0s 151us/step - loss: 10.4475 - acc: 0.3515\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 0s 147us/step - loss: 10.7448 - acc: 0.3325\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 0s 144us/step - loss: 10.6061 - acc: 0.3415\n",
      "2000/2000 [==============================] - 0s 104us/step\n",
      "testing accuracy: 32.50%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_classifier': 0.917,\n",
       " 'logistic_regression_classifier': 0.8345,\n",
       " 'decision_tree_classifier': 0.7185,\n",
       " 'svm_classifier': 0.1,\n",
       " 'random_forest_classifier': 0.848,\n",
       " 'cnn_classifier': 0.2975,\n",
       " 'dnn_classifier': 0.325}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_process(classifiers, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有normalization，没有PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Classifier: knn_classifier\n",
      "training accuracy: 94.50%\n",
      "testing accuracy: 91.70%\n",
      "=======================\n",
      "Classifier: logistic_regression_classifier\n",
      "training accuracy: 98.60%\n",
      "testing accuracy: 88.50%\n",
      "=======================\n",
      "Classifier: decision_tree_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 72.50%\n",
      "=======================\n",
      "Classifier: svm_classifier\n",
      "training accuracy: 98.25%\n",
      "testing accuracy: 93.35%\n",
      "=======================\n",
      "Classifier: random_forest_classifier\n",
      "training accuracy: 99.90%\n",
      "testing accuracy: 84.65%\n",
      "=======================\n",
      "Classifier: cnn_classifier\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 1.9489 - acc: 0.5500\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.9724 - acc: 0.7845\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.4983 - acc: 0.8635\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.3629 - acc: 0.8935\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.2881 - acc: 0.9180\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.2386 - acc: 0.9295\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.2132 - acc: 0.9385\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.1815 - acc: 0.9470\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.1630 - acc: 0.9575\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.1623 - acc: 0.9520\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 17s 9ms/step - loss: 0.1327 - acc: 0.9640\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1228 - acc: 0.9655\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1081 - acc: 0.9705\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0997 - acc: 0.9720\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0850 - acc: 0.9770\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0788 - acc: 0.9790\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0775 - acc: 0.9780\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0655 - acc: 0.9835\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0554 - acc: 0.9850\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0504 - acc: 0.9885\n",
      "2000/2000 [==============================] - 6s 3ms/step\n",
      "testing accuracy: 94.75%\n",
      "=======================\n",
      "Classifier: dnn_classifier\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 1s 333us/step - loss: 1.0140 - acc: 0.6770\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 0s 143us/step - loss: 0.3970 - acc: 0.8725\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 0s 143us/step - loss: 0.2771 - acc: 0.9120\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 0s 146us/step - loss: 0.2172 - acc: 0.9340\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 0s 146us/step - loss: 0.1492 - acc: 0.9545\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 0s 145us/step - loss: 0.0993 - acc: 0.9720\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 0s 144us/step - loss: 0.0848 - acc: 0.9715\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 0s 147us/step - loss: 0.0626 - acc: 0.9795\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 0s 149us/step - loss: 0.0300 - acc: 0.9920\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 0s 163us/step - loss: 0.0392 - acc: 0.9880\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 0s 158us/step - loss: 0.0278 - acc: 0.9925\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 0s 166us/step - loss: 0.0113 - acc: 0.9985\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 0s 148us/step - loss: 0.0212 - acc: 0.9925\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 0s 145us/step - loss: 0.0141 - acc: 0.9950\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 0s 144us/step - loss: 0.0127 - acc: 0.9955\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 0s 141us/step - loss: 0.0054 - acc: 0.9990\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 0s 143us/step - loss: 0.0138 - acc: 0.9965\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 0s 142us/step - loss: 0.0064 - acc: 0.9990\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 0s 145us/step - loss: 0.0076 - acc: 0.9975\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 0s 148us/step - loss: 0.0049 - acc: 0.9980\n",
      "2000/2000 [==============================] - 0s 120us/step\n",
      "testing accuracy: 92.80%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_classifier': 0.917,\n",
       " 'logistic_regression_classifier': 0.885,\n",
       " 'decision_tree_classifier': 0.725,\n",
       " 'svm_classifier': 0.9335,\n",
       " 'random_forest_classifier': 0.8465,\n",
       " 'cnn_classifier': 0.9475,\n",
       " 'dnn_classifier': 0.928}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_process(classifiers, x_train/255, y_train, x_test/255, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 没有normalization，有PCA\n",
    "* CNN不适用于PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练PCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA_model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Classifier: knn_classifier\n",
      "training accuracy: 94.50%\n",
      "testing accuracy: 91.70%\n",
      "=======================\n",
      "Classifier: logistic_regression_classifier\n",
      "training accuracy: 99.85%\n",
      "testing accuracy: 75.95%\n",
      "=======================\n",
      "Classifier: decision_tree_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 64.45%\n",
      "=======================\n",
      "Classifier: svm_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 90.10%\n",
      "=======================\n",
      "Classifier: dnn_classifier\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 1s 285us/step - loss: 13.0490 - acc: 0.1900\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 0s 128us/step - loss: 11.0509 - acc: 0.3090\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 0s 127us/step - loss: 10.2640 - acc: 0.3560\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 0s 135us/step - loss: 9.4031 - acc: 0.4105\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 0s 126us/step - loss: 8.8793 - acc: 0.4425\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 0s 127us/step - loss: 8.6636 - acc: 0.4580\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 0s 124us/step - loss: 8.3827 - acc: 0.4775\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 0s 130us/step - loss: 8.4196 - acc: 0.4735\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 0s 136us/step - loss: 8.2628 - acc: 0.4840\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 0s 129us/step - loss: 8.0690 - acc: 0.4950\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 0s 131us/step - loss: 8.0612 - acc: 0.4970\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 0s 158us/step - loss: 7.9408 - acc: 0.5045\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 0s 173us/step - loss: 8.0656 - acc: 0.4975\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 1s 267us/step - loss: 7.7122 - acc: 0.5200\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 0s 146us/step - loss: 7.6962 - acc: 0.5205\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 0s 141us/step - loss: 7.6741 - acc: 0.5210\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 0s 133us/step - loss: 7.6702 - acc: 0.5230\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 0s 135us/step - loss: 7.6322 - acc: 0.5250\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 0s 135us/step - loss: 7.8189 - acc: 0.5130\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 0s 135us/step - loss: 7.4864 - acc: 0.5335\n",
      "2000/2000 [==============================] - 0s 108us/step\n",
      "testing accuracy: 51.40%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_classifier': 0.917,\n",
       " 'logistic_regression_classifier': 0.7595,\n",
       " 'decision_tree_classifier': 0.6445,\n",
       " 'svm_classifier': 0.901,\n",
       " 'dnn_classifier': 0.514}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pca = pca_model.transform(x_train)\n",
    "x_test_pca = pca_model.transform(x_test)\n",
    "temp_classifiers = ['knn_classifier','logistic_regression_classifier','decision_tree_classifier','svm_classifier','dnn_classifier'] # 没有CNN\n",
    "training_process(temp_classifiers, x_train_pca, y_train, x_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有normalization和PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Classifier: knn_classifier\n",
      "training accuracy: 94.55%\n",
      "testing accuracy: 91.70%\n",
      "=======================\n",
      "Classifier: logistic_regression_classifier\n",
      "training accuracy: 98.35%\n",
      "testing accuracy: 87.90%\n",
      "=======================\n",
      "Classifier: decision_tree_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 64.40%\n",
      "=======================\n",
      "Classifier: svm_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 90.10%\n",
      "=======================\n",
      "Classifier: dnn_classifier\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 1s 277us/step - loss: 0.9646 - acc: 0.7305\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 0s 107us/step - loss: 0.3099 - acc: 0.9205\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 0s 105us/step - loss: 0.1685 - acc: 0.9590\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 0s 107us/step - loss: 0.1037 - acc: 0.9740\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 0s 106us/step - loss: 0.0497 - acc: 0.9905\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 0s 106us/step - loss: 0.0270 - acc: 0.9970\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 0s 106us/step - loss: 0.0180 - acc: 0.9975\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 0s 109us/step - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 0s 107us/step - loss: 0.0071 - acc: 0.9995\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 0s 108us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 0s 107us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 0s 109us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 0s 108us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 0s 109us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 0s 109us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 0s 107us/step - loss: 5.9898e-04 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 0s 109us/step - loss: 8.6944e-04 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 0s 111us/step - loss: 5.3377e-04 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 0s 110us/step - loss: 3.9045e-04 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 0s 108us/step - loss: 2.7384e-04 - acc: 1.0000\n",
      "2000/2000 [==============================] - 0s 98us/step\n",
      "testing accuracy: 91.15%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_classifier': 0.917,\n",
       " 'logistic_regression_classifier': 0.879,\n",
       " 'decision_tree_classifier': 0.644,\n",
       " 'svm_classifier': 0.901,\n",
       " 'dnn_classifier': 0.9115}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_model = PCA_model(x_train/255,components=400)\n",
    "x_train_normal_pca = pca_model.transform(x_train/255)\n",
    "x_test_normal_pca = pca_model.transform(x_test/255)\n",
    "temp_classifiers = ['knn_classifier','logistic_regression_classifier','decision_tree_classifier','svm_classifier','dnn_classifier'] # 没有CNN\n",
    "training_process(temp_classifiers, x_train_normal_pca, y_train, x_test_normal_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
