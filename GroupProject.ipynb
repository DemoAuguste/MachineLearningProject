{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import pca\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取MNIST数据\n",
    "* 两组数据\n",
    "* 1. train 1-2000, test 2001-4000\n",
    "* 2. train 2001-4000, test 1-2000\n",
    "* 数据是按0-9的顺序排列的，每个数字有两百个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(flag=1,normalize=False):\n",
    "    \"\"\"\n",
    "    flag: 选择两组数据中的某一个\n",
    "    normalize: 数据是否要正则化 (在训练某些model的时候好像有bug，待研究)\n",
    "    \n",
    "    return: X_train, Y_train, X_test, Y_test\n",
    "    \"\"\"\n",
    "    labels = get_data('digits4000_txt/digits4000_digits_labels.txt')\n",
    "    digits = get_data('digits4000_txt/digits4000_digits_vec.txt')\n",
    "\n",
    "    if flag==1:\n",
    "        X_train = digits[:2000]\n",
    "        Y_train = labels[:2000]\n",
    "        X_test = digits[2000:]\n",
    "        Y_test = labels[2000:]\n",
    "    else:\n",
    "        X_train = digits[2000:]\n",
    "        Y_train = labels[2000:]\n",
    "        X_test = digits[:2000]\n",
    "        Y_test = labels[:2000]\n",
    "\n",
    "    if normalize:\n",
    "        X_train = X_train/255\n",
    "        Y_train = Y_train/255\n",
    "        X_test = X_test/255\n",
    "        Y_test = Y_test/255\n",
    "\n",
    "    return np.array(X_train),np.array(Y_train),np.array(X_test),np.array(Y_test)\n",
    "\n",
    "def get_data(filename):\n",
    "    return np.loadtxt(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各种Classifier的实现\n",
    "\n",
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(train_x,train_y):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    model = KNeighborsClassifier()\n",
    "    model.fit(train_x, train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_classifier(train_x, train_y):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    model = LogisticRegression(penalty='l2')\n",
    "    model.fit(train_x, train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_classifier(train_x, train_y):\n",
    "    from sklearn import tree\n",
    "    model = tree.DecisionTreeClassifier()\n",
    "    model.fit(train_x, train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_classifier(train_x, train_y):\n",
    "    from sklearn.svm import SVC\n",
    "    model = SVC(kernel='linear', gamma=0.01, C=1)\n",
    "    model.fit(train_x, train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model\n",
    "* 模型参数直接在这个里面改\n",
    "* CNN不需要进行PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_classifier(train_x, train_y):\n",
    "    train_X = train_x.reshape(-1, 1, 28, 28)\n",
    "    train_Y = np_utils.to_categorical(train_y, num_classes=10)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Convolution2D(filters=32,\n",
    "                                        kernel_size=5,\n",
    "                                        strides=1,\n",
    "                                        padding='same',\n",
    "                                        batch_input_shape=(None, 1, 28, 28),\n",
    "                                        data_format='channels_first'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2, \n",
    "                                       strides=2, \n",
    "                                       padding='same', \n",
    "                                       data_format='channels_first'))\n",
    "    model.add(Convolution2D(64, 5, \n",
    "                                        strides=1, \n",
    "                                        padding='same', \n",
    "                                        data_format='channels_first'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = Adam(lr=1e-4)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(train_X, train_Y, epochs=20, batch_size=64)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN model\n",
    "* 和CNN model相似，结构不一样\n",
    "* DNN可以进行PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_classifier(train_x, train_y):\n",
    "    batch_size = 100\n",
    "    nb_classes = 10\n",
    "    nb_epoch = 20\n",
    "    \n",
    "    train_y = np_utils.to_categorical(train_y, num_classes=10)\n",
    "    \n",
    "    input_dim = train_x.shape[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(input_dim,)))\n",
    "    \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "    model.fit(train_x, train_y, batch_size=batch_size, epochs=nb_epoch)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用PCA降维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_model(train_x,components=600):\n",
    "    model = pca.PCA(n_components=components).fit(train_x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training和testing的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers = ['knn_classifier','logistic_regression_classifier','decision_tree_classifier','svm_classifier','cnn_classifier','dnn_classifier']\n",
    "classifiers = ['knn_classifier','logistic_regression_classifier','decision_tree_classifier','svm_classifier','dnn_classifier'] # test\n",
    "x_train, y_train, x_test, y_test = load_data(flag=1,normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_process(classifiers, x_train, y_train, x_test, y_test):\n",
    "    result = {}\n",
    "    for classifier in classifiers:\n",
    "        try:\n",
    "            print(\"=======================\")\n",
    "            print('Classifier: {}'.format(classifier))\n",
    "            temp_model = eval(classifier)(x_train,y_train) \n",
    "    \n",
    "            if classifier == 'cnn_classifier': # CNN需要转换一下数据格式\n",
    "                x_test_reshape = x_test.reshape(-1, 1, 28, 28)\n",
    "                y_test_reshape = np_utils.to_categorical(y_test, num_classes=10)\n",
    "                loss, accuracy = temp_model.evaluate(x_test_reshape, y_test_reshape)\n",
    "            else:\n",
    "                if classifier == 'dnn_classifier':\n",
    "                    y_test_reshape = np_utils.to_categorical(y_test, num_classes=10)\n",
    "                    loss, accuracy = temp_model.evaluate(x_test, y_test_reshape)\n",
    "                else:\n",
    "                    y_train_predict = temp_model.predict(x_train)\n",
    "                    training_accuracy = metrics.accuracy_score(y_train,y_train_predict)\n",
    "                    print('training accuracy: {}'.format(\"%.2f%%\"%( 100*training_accuracy)))\n",
    "                    y_predict = temp_model.predict(x_test)\n",
    "                    accuracy = metrics.accuracy_score(y_test, y_predict)\n",
    "                \n",
    "            print('testing accuracy: {}'.format(\"%.2f%%\"%( 100*accuracy)))\n",
    "            result[classifier] = accuracy\n",
    "        except:\n",
    "            print('+++++++++++++++++++++++++')\n",
    "            print('Error with {}.'.format(classifier))\n",
    "            import traceback\n",
    "            print(traceback.format_exc())\n",
    "            print('+++++++++++++++++++++++++')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 没有normalization和PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Classifier: knn_classifier\n",
      "training accuracy: 94.50%\n",
      "testing accuracy: 91.70%\n",
      "=======================\n",
      "Classifier: logistic_regression_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 83.45%\n",
      "=======================\n",
      "Classifier: decision_tree_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 72.80%\n",
      "=======================\n",
      "Classifier: svm_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 90.10%\n",
      "=======================\n",
      "Classifier: dnn_classifier\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 1s 408us/step - loss: 14.3917 - acc: 0.1060\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 0s 145us/step - loss: 12.5075 - acc: 0.2190\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 0s 141us/step - loss: 11.0118 - acc: 0.3130\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 0s 141us/step - loss: 10.6451 - acc: 0.3365\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 0s 142us/step - loss: 10.2776 - acc: 0.3620\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 0s 144us/step - loss: 10.5612 - acc: 0.3430\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 0s 142us/step - loss: 10.9011 - acc: 0.3230\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 0s 141us/step - loss: 10.4264 - acc: 0.3515\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 0s 147us/step - loss: 10.2002 - acc: 0.3665\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 0s 153us/step - loss: 10.2623 - acc: 0.3630\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 0s 147us/step - loss: 10.1876 - acc: 0.3670\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 0s 143us/step - loss: 10.3577 - acc: 0.3550\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 0s 142us/step - loss: 10.0255 - acc: 0.3780\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 0s 141us/step - loss: 10.2086 - acc: 0.3655\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 0s 141us/step - loss: 10.2609 - acc: 0.3630\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 0s 145us/step - loss: 10.4399 - acc: 0.3515\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 0s 144us/step - loss: 9.9254 - acc: 0.3840\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 0s 145us/step - loss: 9.9692 - acc: 0.3810\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 0s 144us/step - loss: 9.9368 - acc: 0.3835\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 0s 143us/step - loss: 10.0237 - acc: 0.3775\n",
      "2000/2000 [==============================] - 0s 150us/step\n",
      "testing accuracy: 37.10%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_classifier': 0.917,\n",
       " 'logistic_regression_classifier': 0.8345,\n",
       " 'decision_tree_classifier': 0.728,\n",
       " 'svm_classifier': 0.901,\n",
       " 'dnn_classifier': 0.371}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_process(classifiers, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有normalization，没有PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Classifier: knn_classifier\n",
      "training accuracy: 94.50%\n",
      "testing accuracy: 91.70%\n",
      "=======================\n",
      "Classifier: logistic_regression_classifier\n",
      "training accuracy: 98.60%\n",
      "testing accuracy: 88.50%\n",
      "=======================\n",
      "Classifier: decision_tree_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 72.85%\n",
      "=======================\n",
      "Classifier: svm_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 90.10%\n",
      "=======================\n",
      "Classifier: dnn_classifier\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 1s 431us/step - loss: 1.0827 - acc: 0.6450\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 0s 141us/step - loss: 0.3991 - acc: 0.8800\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 0s 140us/step - loss: 0.2818 - acc: 0.9140\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 0s 144us/step - loss: 0.1920 - acc: 0.9460\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 0s 142us/step - loss: 0.1462 - acc: 0.9560\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 0s 151us/step - loss: 0.0942 - acc: 0.9725\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 0s 220us/step - loss: 0.0721 - acc: 0.9775\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 0s 187us/step - loss: 0.0587 - acc: 0.9825\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 0s 142us/step - loss: 0.0581 - acc: 0.9800\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 0s 168us/step - loss: 0.0258 - acc: 0.9935\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 0s 162us/step - loss: 0.0248 - acc: 0.9940\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 0s 159us/step - loss: 0.0330 - acc: 0.9920\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 0s 171us/step - loss: 0.0121 - acc: 0.9975\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 0s 172us/step - loss: 0.0105 - acc: 0.9975\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 0s 159us/step - loss: 0.0326 - acc: 0.9920\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 0s 151us/step - loss: 0.0103 - acc: 0.9975\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 0s 185us/step - loss: 0.0099 - acc: 0.9970\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 0s 207us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 0s 177us/step - loss: 0.0099 - acc: 0.9975\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 0s 192us/step - loss: 0.0167 - acc: 0.9955\n",
      "2000/2000 [==============================] - 0s 206us/step\n",
      "testing accuracy: 93.05%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_classifier': 0.917,\n",
       " 'logistic_regression_classifier': 0.885,\n",
       " 'decision_tree_classifier': 0.7285,\n",
       " 'svm_classifier': 0.901,\n",
       " 'dnn_classifier': 0.9305}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_process(classifiers, x_train/255, y_train, x_test/255, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 没有normalization，有PCA\n",
    "* CNN不适用于PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练PCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA_model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Classifier: knn_classifier\n",
      "training accuracy: 94.50%\n",
      "testing accuracy: 91.70%\n",
      "=======================\n",
      "Classifier: logistic_regression_classifier\n",
      "training accuracy: 99.90%\n",
      "testing accuracy: 76.75%\n",
      "=======================\n",
      "Classifier: decision_tree_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 63.90%\n",
      "=======================\n",
      "Classifier: svm_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 90.10%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_classifier': 0.917,\n",
       " 'logistic_regression_classifier': 0.7675,\n",
       " 'decision_tree_classifier': 0.639,\n",
       " 'svm_classifier': 0.901}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pca = pca_model.transform(x_train)\n",
    "x_test_pca = pca_model.transform(x_test)\n",
    "temp_classifiers = ['knn_classifier','logistic_regression_classifier','decision_tree_classifier','svm_classifier'] # 没有CNN\n",
    "training_process(temp_classifiers, x_train_pca, y_train, x_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有normalization和PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Classifier: knn_classifier\n",
      "training accuracy: 94.55%\n",
      "testing accuracy: 91.75%\n",
      "=======================\n",
      "Classifier: logistic_regression_classifier\n",
      "training accuracy: 98.30%\n",
      "testing accuracy: 87.80%\n",
      "=======================\n",
      "Classifier: decision_tree_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 65.70%\n",
      "=======================\n",
      "Classifier: svm_classifier\n",
      "training accuracy: 100.00%\n",
      "testing accuracy: 90.10%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_classifier': 0.9175,\n",
       " 'logistic_regression_classifier': 0.878,\n",
       " 'decision_tree_classifier': 0.657,\n",
       " 'svm_classifier': 0.901}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_model = PCA_model(x_train/255,components=400)\n",
    "x_train_normal_pca = pca_model.transform(x_train/255)\n",
    "x_test_normal_pca = pca_model.transform(x_test/255)\n",
    "temp_classifiers = ['knn_classifier','logistic_regression_classifier','decision_tree_classifier','svm_classifier'] # 没有CNN\n",
    "training_process(temp_classifiers, x_train_normal_pca, y_train, x_test_normal_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
