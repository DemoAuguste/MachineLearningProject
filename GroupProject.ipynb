{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import pca\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取MNIST数据\n",
    "* 两组数据\n",
    "* 1. train 1-2000, test 2001-4000\n",
    "* 2. train 2001-4000, test 1-2000\n",
    "* 数据是按0-9的顺序排列的，每个数字有两百个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(flag=1,normalize=False):\n",
    "    \"\"\"\n",
    "    flag: 选择两组数据中的某一个\n",
    "    normalize: 数据是否要正则化 (在训练某些model的时候好像有bug，待研究)\n",
    "    \n",
    "    return: X_train, Y_train, X_test, Y_test\n",
    "    \"\"\"\n",
    "    labels = get_data('digits4000_txt/digits4000_digits_labels.txt')\n",
    "    digits = get_data('digits4000_txt/digits4000_digits_vec.txt')\n",
    "\n",
    "    if flag==1:\n",
    "        X_train = digits[:2000]\n",
    "        Y_train = labels[:2000]\n",
    "        X_test = digits[2000:]\n",
    "        Y_test = labels[2000:]\n",
    "    else:\n",
    "        X_train = digits[2000:]\n",
    "        Y_train = labels[2000:]\n",
    "        X_test = digits[:2000]\n",
    "        Y_test = labels[:2000]\n",
    "\n",
    "    if normalize:\n",
    "        X_train = X_train/255\n",
    "        Y_train = Y_train\n",
    "        X_test = X_test/255\n",
    "        Y_test = Y_test\n",
    "\n",
    "    return np.array(X_train),np.array(Y_train),np.array(X_test),np.array(Y_test)\n",
    "\n",
    "def get_data(filename):\n",
    "    return np.loadtxt(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data(flag=1,normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各种Classifier的实现\n",
    "\n",
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(train_x,train_y):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    model = KNeighborsClassifier()\n",
    "    model.fit(train_x, train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_classifier(train_x, train_y):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    model = LogisticRegression(penalty='l2')\n",
    "    model.fit(train_x, train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_classifier(train_x, train_y):\n",
    "    from sklearn import tree\n",
    "    model = tree.DecisionTreeClassifier()\n",
    "    model.fit(train_x, train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_classifier(train_x, train_y):\n",
    "    from sklearn.svm import SVC\n",
    "    model = SVC(kernel='rbf', gamma=0.01, C=1) # 选择kernel之后，rbf的准确率比其他的高，参数还没研究过\n",
    "    model.fit(train_x, train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifier(train_x, train_y, num_classes=10):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(train_x, train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_boost_classifier(train_x, train_y, num_classes=10):\n",
    "\tfrom sklearn.ensemble import AdaBoostClassifier\n",
    "\tmodel = AdaBoostClassifier()\n",
    "\tmodel.fit(train_x,train_y)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model\n",
    "* 模型参数直接在这个里面改\n",
    "* CNN不需要进行PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_classifier(train_x, train_y):\n",
    "    train_X = train_x.reshape(-1, 1, 28, 28)\n",
    "    train_Y = np_utils.to_categorical(train_y, num_classes=10)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Convolution2D(filters=32,\n",
    "                                        kernel_size=5,\n",
    "                                        strides=1,\n",
    "                                        padding='same',\n",
    "                                        batch_input_shape=(None, 1, 28, 28),\n",
    "                                        data_format='channels_first'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2, \n",
    "                                       strides=2, \n",
    "                                       padding='same', \n",
    "                                       data_format='channels_first'))\n",
    "    model.add(Convolution2D(64, 5, \n",
    "                                        strides=1, \n",
    "                                        padding='same', \n",
    "                                        data_format='channels_first'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = Adam(lr=1e-4)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(train_X, train_Y, epochs=20, batch_size=64)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN model\n",
    "* 和CNN model相似，结构不一样\n",
    "* DNN可以进行PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_classifier(train_x, train_y):\n",
    "    batch_size = 100\n",
    "    nb_classes = 10\n",
    "    nb_epoch = 20\n",
    "    \n",
    "    train_y = np_utils.to_categorical(train_y, num_classes=10)\n",
    "    \n",
    "    input_dim = train_x.shape[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(input_dim,)))\n",
    "    \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "    model.fit(train_x, train_y, batch_size=batch_size, epochs=nb_epoch)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用PCA降维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_model(train_x,components=150):\n",
    "    model = pca.PCA(n_components=components).fit(train_x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training和testing的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['knn_classifier','logistic_regression_classifier','decision_tree_classifier','svm_classifier','random_forest_classifier','ada_boost_classifier','cnn_classifier','dnn_classifier']\n",
    "# classifiers = ['knn_classifier','logistic_regression_classifier','decision_tree_classifier','svm_classifier','dnn_classifier'] # test\n",
    "# x_train, y_train, x_test, y_test = load_data(flag=1,normalize=False)\n",
    "x_train, y_train, x_test, y_test = load_data(flag=1,normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_process(classifiers, x_train, y_train, x_test, y_test):\n",
    "    result = {}\n",
    "    for classifier in classifiers:\n",
    "        try:\n",
    "            print(\"=======================\")\n",
    "            print('Classifier: {}'.format(classifier))\n",
    "            temp_model = eval(classifier)(x_train,y_train) \n",
    "    \n",
    "            if classifier == 'cnn_classifier': # CNN需要转换一下数据格式\n",
    "                x_test_reshape = x_test.reshape(-1, 1, 28, 28)\n",
    "                y_test_reshape = np_utils.to_categorical(y_test, num_classes=10)\n",
    "                loss, accuracy = temp_model.evaluate(x_test_reshape, y_test_reshape)\n",
    "            else:\n",
    "                if classifier == 'dnn_classifier':\n",
    "                    y_test_reshape = np_utils.to_categorical(y_test, num_classes=10)\n",
    "                    loss, accuracy = temp_model.evaluate(x_test, y_test_reshape)\n",
    "                else:\n",
    "                    y_train_predict = temp_model.predict(x_train)\n",
    "                    training_accuracy = metrics.accuracy_score(y_train,y_train_predict)\n",
    "                    print('training accuracy: {}'.format(training_accuracy))\n",
    "                    y_predict = temp_model.predict(x_test)\n",
    "                    accuracy = metrics.accuracy_score(y_test, y_predict)\n",
    "                \n",
    "            print('testing accuracy: {}'.format(accuracy))\n",
    "            result[classifier] = accuracy\n",
    "        except:\n",
    "            print('+++++++++++++++++++++++++')\n",
    "            print('Error with {}.'.format(classifier))\n",
    "            import traceback\n",
    "            print(traceback.format_exc())\n",
    "            print('+++++++++++++++++++++++++')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 没有normalization和PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Classifier: knn_classifier\n",
      "training accuracy: 0.9465\n",
      "testing accuracy: 0.9095\n",
      "=======================\n",
      "Classifier: logistic_regression_classifier\n",
      "training accuracy: 1.0\n",
      "testing accuracy: 0.8395\n",
      "=======================\n",
      "Classifier: decision_tree_classifier\n",
      "training accuracy: 1.0\n",
      "testing accuracy: 0.6845\n",
      "=======================\n",
      "Classifier: svm_classifier\n",
      "training accuracy: 1.0\n",
      "testing accuracy: 0.1\n",
      "=======================\n",
      "Classifier: random_forest_classifier\n",
      "training accuracy: 0.9995\n",
      "testing accuracy: 0.823\n",
      "=======================\n",
      "Classifier: ada_boost_classifier\n",
      "training accuracy: 0.4485\n",
      "testing accuracy: 0.4085\n",
      "=======================\n",
      "Classifier: cnn_classifier\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 11.7067 - acc: 0.2530\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 11.3379 - acc: 0.2945\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 11.3280 - acc: 0.2965\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 11.3295 - acc: 0.2965\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 11.4279 - acc: 0.2870\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 11.3508 - acc: 0.2930\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 11.2324 - acc: 0.2985\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 9.9236 - acc: 0.3785\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 9.8224 - acc: 0.3865\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 9.7900 - acc: 0.3900\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 9.7320 - acc: 0.3950\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 9.7279 - acc: 0.3955\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 9.7001 - acc: 0.3965\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 9.7129 - acc: 0.3965\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 9.7313 - acc: 0.3950\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 9.7106 - acc: 0.3965\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 9.7013 - acc: 0.3970\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 9.6826 - acc: 0.3990\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 9.7079 - acc: 0.3965\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 9.6826 - acc: 0.3980\n",
      "2000/2000 [==============================] - 6s 3ms/step\n",
      "testing accuracy: 0.3895\n",
      "=======================\n",
      "Classifier: dnn_classifier\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 1s 412us/step - loss: 14.4336 - acc: 0.1040\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 0s 154us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 0s 148us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 0s 147us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 0s 147us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 0s 152us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 0s 150us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 0s 147us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 0s 146us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 0s 145us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 0s 145us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 0s 148us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 0s 146us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 0s 147us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 0s 146us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 0s 151us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 0s 165us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 0s 152us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 0s 170us/step - loss: 14.5063 - acc: 0.1000\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 0s 149us/step - loss: 14.5063 - acc: 0.1000\n",
      "2000/2000 [==============================] - 0s 155us/step\n",
      "testing accuracy: 0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_classifier': 0.9095,\n",
       " 'logistic_regression_classifier': 0.8395,\n",
       " 'decision_tree_classifier': 0.6845,\n",
       " 'svm_classifier': 0.1,\n",
       " 'random_forest_classifier': 0.823,\n",
       " 'ada_boost_classifier': 0.4085,\n",
       " 'cnn_classifier': 0.3895,\n",
       " 'dnn_classifier': 0.1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    training_process(classifiers, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有normalization，没有PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Classifier: knn_classifier\n",
      "training accuracy: 0.9465\n",
      "testing accuracy: 0.9095\n",
      "=======================\n",
      "Classifier: logistic_regression_classifier\n",
      "training accuracy: 0.989\n",
      "testing accuracy: 0.8755\n",
      "=======================\n",
      "Classifier: decision_tree_classifier\n",
      "training accuracy: 1.0\n",
      "testing accuracy: 0.681\n",
      "=======================\n",
      "Classifier: svm_classifier\n",
      "training accuracy: 0.9795\n",
      "testing accuracy: 0.9275\n",
      "=======================\n",
      "Classifier: random_forest_classifier\n",
      "training accuracy: 0.999\n",
      "testing accuracy: 0.8465\n",
      "=======================\n",
      "Classifier: ada_boost_classifier\n",
      "training accuracy: 0.4485\n",
      "testing accuracy: 0.4085\n",
      "=======================\n",
      "Classifier: cnn_classifier\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 1.9718 - acc: 0.6000\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.9811 - acc: 0.8005\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5088 - acc: 0.8555\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3646 - acc: 0.8955\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2838 - acc: 0.9165\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2416 - acc: 0.9330\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2112 - acc: 0.9385\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 17s 8ms/step - loss: 0.1845 - acc: 0.9460\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1572 - acc: 0.9525\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1434 - acc: 0.9560\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.1377 - acc: 0.9595\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1155 - acc: 0.9670\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.1011 - acc: 0.9720\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0894 - acc: 0.9770\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0939 - acc: 0.9715\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0754 - acc: 0.9805\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0630 - acc: 0.9850\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0570 - acc: 0.9855\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0530 - acc: 0.9870\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0462 - acc: 0.9910\n",
      "2000/2000 [==============================] - 6s 3ms/step\n",
      "testing accuracy: 0.949\n",
      "=======================\n",
      "Classifier: dnn_classifier\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 1s 442us/step - loss: 1.0496 - acc: 0.6550\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 0s 148us/step - loss: 0.4009 - acc: 0.8770\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 0s 146us/step - loss: 0.2826 - acc: 0.9125\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 0s 147us/step - loss: 0.1873 - acc: 0.9400\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 0s 183us/step - loss: 0.1479 - acc: 0.9500\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 0s 171us/step - loss: 0.1210 - acc: 0.9675\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 0s 240us/step - loss: 0.0795 - acc: 0.9725\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 0s 233us/step - loss: 0.0516 - acc: 0.9840\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 0s 210us/step - loss: 0.0628 - acc: 0.9805\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 0s 207us/step - loss: 0.0267 - acc: 0.9930\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 0s 209us/step - loss: 0.0343 - acc: 0.9895\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 1s 253us/step - loss: 0.0344 - acc: 0.9900\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 0s 154us/step - loss: 0.0122 - acc: 0.9965\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 0s 146us/step - loss: 0.0168 - acc: 0.9960\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 0s 149us/step - loss: 0.0229 - acc: 0.9955\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 0s 148us/step - loss: 0.0053 - acc: 0.9995\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 0s 148us/step - loss: 0.0065 - acc: 0.9980\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 0s 150us/step - loss: 0.0193 - acc: 0.9935\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 0s 153us/step - loss: 0.0103 - acc: 0.9980\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 0s 159us/step - loss: 0.0232 - acc: 0.9950\n",
      "2000/2000 [==============================] - 0s 170us/step\n",
      "testing accuracy: 0.919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_classifier': 0.9095,\n",
       " 'logistic_regression_classifier': 0.8755,\n",
       " 'decision_tree_classifier': 0.681,\n",
       " 'svm_classifier': 0.9275,\n",
       " 'random_forest_classifier': 0.8465,\n",
       " 'ada_boost_classifier': 0.4085,\n",
       " 'cnn_classifier': 0.949,\n",
       " 'dnn_classifier': 0.919}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_process(classifiers, x_train/255, y_train, x_test/255, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 没有normalization，有PCA\n",
    "* CNN不适用于PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练PCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA_model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Classifier: knn_classifier\n",
      "training accuracy: 0.95\n",
      "testing accuracy: 0.9195\n",
      "=======================\n",
      "Classifier: logistic_regression_classifier\n",
      "training accuracy: 0.9775\n",
      "testing accuracy: 0.8555\n",
      "=======================\n",
      "Classifier: decision_tree_classifier\n",
      "training accuracy: 1.0\n",
      "testing accuracy: 0.6835\n",
      "=======================\n",
      "Classifier: svm_classifier\n",
      "training accuracy: 1.0\n",
      "testing accuracy: 0.1005\n",
      "=======================\n",
      "Classifier: random_forest_classifier\n",
      "training accuracy: 0.9995\n",
      "testing accuracy: 0.7175\n",
      "=======================\n",
      "Classifier: ada_boost_classifier\n",
      "training accuracy: 0.309\n",
      "testing accuracy: 0.2995\n",
      "=======================\n",
      "Classifier: dnn_classifier\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 1s 404us/step - loss: 12.1179 - acc: 0.2440\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 0s 88us/step - loss: 11.6124 - acc: 0.2785\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 0s 88us/step - loss: 11.4796 - acc: 0.2875\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 0s 88us/step - loss: 11.3868 - acc: 0.2935\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 0s 91us/step - loss: 10.5508 - acc: 0.3420\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 0s 93us/step - loss: 10.1304 - acc: 0.3710\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 10.0053 - acc: 0.3790\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 0s 91us/step - loss: 10.1816 - acc: 0.3680\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 0s 97us/step - loss: 10.1573 - acc: 0.3690\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 0s 138us/step - loss: 9.6761 - acc: 0.3980\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 0s 100us/step - loss: 8.8916 - acc: 0.4455\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 0s 94us/step - loss: 8.6136 - acc: 0.4655\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 0s 125us/step - loss: 8.6071 - acc: 0.4660\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 0s 88us/step - loss: 8.8648 - acc: 0.4490\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 0s 89us/step - loss: 8.5848 - acc: 0.4670\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 0s 92us/step - loss: 8.5418 - acc: 0.4695\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 0s 151us/step - loss: 8.6042 - acc: 0.4660\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 0s 170us/step - loss: 8.6621 - acc: 0.4615\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 0s 134us/step - loss: 8.4017 - acc: 0.4775\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 0s 108us/step - loss: 8.4695 - acc: 0.4730\n",
      "2000/2000 [==============================] - 0s 162us/step\n",
      "testing accuracy: 0.476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_classifier': 0.9195,\n",
       " 'logistic_regression_classifier': 0.8555,\n",
       " 'decision_tree_classifier': 0.6835,\n",
       " 'svm_classifier': 0.1005,\n",
       " 'random_forest_classifier': 0.7175,\n",
       " 'ada_boost_classifier': 0.2995,\n",
       " 'dnn_classifier': 0.476}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pca = pca_model.transform(x_train)\n",
    "x_test_pca = pca_model.transform(x_test)\n",
    "temp_classifiers = ['knn_classifier','logistic_regression_classifier','decision_tree_classifier','svm_classifier','random_forest_classifier','ada_boost_classifier','dnn_classifier'] # 没有CNN\n",
    "training_process(temp_classifiers, x_train_pca, y_train, x_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有normalization和PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Classifier: knn_classifier\n",
      "training accuracy: 0.949\n",
      "testing accuracy: 0.9185\n",
      "=======================\n",
      "Classifier: logistic_regression_classifier\n",
      "training accuracy: 0.9605\n",
      "testing accuracy: 0.885\n",
      "=======================\n",
      "Classifier: decision_tree_classifier\n",
      "training accuracy: 1.0\n",
      "testing accuracy: 0.6765\n",
      "=======================\n",
      "Classifier: svm_classifier\n",
      "training accuracy: 0.9785\n",
      "testing accuracy: 0.933\n",
      "=======================\n",
      "Classifier: random_forest_classifier\n",
      "training accuracy: 0.997\n",
      "testing accuracy: 0.7165\n",
      "=======================\n",
      "Classifier: ada_boost_classifier\n",
      "training accuracy: 0.309\n",
      "testing accuracy: 0.2995\n",
      "=======================\n",
      "Classifier: dnn_classifier\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 1s 499us/step - loss: 0.9736 - acc: 0.7270\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 0s 174us/step - loss: 0.3365 - acc: 0.9060\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 0s 118us/step - loss: 0.2133 - acc: 0.9390\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 0s 132us/step - loss: 0.1333 - acc: 0.9650\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 0s 107us/step - loss: 0.0864 - acc: 0.9810\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 0s 137us/step - loss: 0.0526 - acc: 0.9925\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 0s 203us/step - loss: 0.0377 - acc: 0.9915\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 0s 115us/step - loss: 0.0231 - acc: 0.9965\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 0s 139us/step - loss: 0.0144 - acc: 0.9975\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 0s 85us/step - loss: 0.0124 - acc: 0.9985\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 0s 116us/step - loss: 0.0117 - acc: 0.9975\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 0s 104us/step - loss: 0.0100 - acc: 0.9980\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 0s 96us/step - loss: 0.0058 - acc: 0.9990\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 0s 178us/step - loss: 0.0056 - acc: 0.9985\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 0s 142us/step - loss: 0.0043 - acc: 0.9990\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 0s 152us/step - loss: 0.0043 - acc: 0.9990\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 0s 85us/step - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 0s 105us/step - loss: 0.0036 - acc: 0.9985\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 0s 94us/step - loss: 9.4483e-04 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 0s 105us/step - loss: 0.0073 - acc: 0.9980\n",
      "2000/2000 [==============================] - 0s 213us/step\n",
      "testing accuracy: 0.922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_classifier': 0.9185,\n",
       " 'logistic_regression_classifier': 0.885,\n",
       " 'decision_tree_classifier': 0.6765,\n",
       " 'svm_classifier': 0.933,\n",
       " 'random_forest_classifier': 0.7165,\n",
       " 'ada_boost_classifier': 0.2995,\n",
       " 'dnn_classifier': 0.922}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_model = PCA_model(x_train/255)\n",
    "x_train_normal_pca = pca_model.transform(x_train/255)\n",
    "x_test_normal_pca = pca_model.transform(x_test/255)\n",
    "temp_classifiers = ['knn_classifier','logistic_regression_classifier','decision_tree_classifier','svm_classifier','random_forest_classifier','ada_boost_classifier','dnn_classifier'] # 没有CNN\n",
    "training_process(temp_classifiers, x_train_normal_pca, y_train, x_test_normal_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
